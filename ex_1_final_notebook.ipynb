{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BarGinger/ExplainableAIRadiology/blob/main/ex_1_final_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "keHYaI-BifsE",
        "outputId": "ea7c6012-e721-433d-d693-4500d65a0ef5"
      },
      "outputs": [],
      "source": [
        "# helper function to check if the code is running in Google Colab\n",
        "def is_colab():\n",
        "    try:\n",
        "        import google.colab\n",
        "        return True\n",
        "    except ImportError:\n",
        "        return False\n",
        "\n",
        "# Usage\n",
        "if is_colab():\n",
        "    print(\"Running in Google Colab\")\n",
        "else:\n",
        "    print(\"Not running in Google Colab\")\n",
        "\n",
        "if is_colab():\n",
        "    # Enable the widgets extension for JupyterLab\n",
        "    %pip install jupyterlab_widgets\n",
        "    %pip install ipywidgets\n",
        "    %pip install --upgrade torchsummary\n",
        "    %pip install torch-summary\n",
        "    %pip install onnx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RwonYEnFZktc"
      },
      "outputs": [],
      "source": [
        "# Importing libraries\n",
        "import pandas as pd\n",
        "# from preprocessing_utils import  get_class_names, get_policies, get_datasets, transform_dataset\n",
        "import numpy as np\n",
        "from IPython.display import display\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.cuda.amp import GradScaler, autocast  # Add these imports for mixed precision training\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "# from training_utils import train_model, predict_model, load_model, plot_roc_curve\n",
        "from torchsummary import summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GaGn3ZUZkti"
      },
      "source": [
        "### Define Global objects"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UF3472WxZkti"
      },
      "outputs": [],
      "source": [
        "# Global helper functions\n",
        "def get_class_names():\n",
        "    return [\n",
        "        'Pleural Effusion'\n",
        "    ]\n",
        "\n",
        "def get_policies():\n",
        "    return [\n",
        "        'ones',\n",
        "        'zeroes',\n",
        "        'mixed'\n",
        "    ]\n",
        "\n",
        "# Global variables\n",
        "\n",
        "# Define the class names for the medical conditions\n",
        "class_names = get_class_names()\n",
        "\n",
        "# Define the policies for dataset preparation\n",
        "policies = get_policies()\n",
        "\n",
        "# Path to the zip file\n",
        "zip_path = \"./chexpert.zip\"\n",
        "\n",
        "# Path to the zip file in Google Drive\n",
        "zip_file_in_drive = '/content/drive/MyDrive/chexpert.zip'  # Change this to your desired location\n",
        "\n",
        "# Path to the directory where the datasets will be extracted\n",
        "data_dir = \"./CheXpert-v1.0-small\"\n",
        "\n",
        "# Set the device to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Set the batch size\n",
        "batch_size = 16\n",
        "\n",
        "# Set pandas display options to show all columns\n",
        "pd.set_option('display.max_columns', None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TXX68RzaZkte"
      },
      "outputs": [],
      "source": [
        "# Check if CUDA is available\n",
        "print(torch.__version__)\n",
        "print(torch.version.cuda)  # Should match CUDA 12.5\n",
        "print(torch.backends.cudnn.version())  # Should return a version, not None\n",
        "print(torch.cuda.is_available())  # Should return True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CZK1HapZkth"
      },
      "source": [
        "# Dataset class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PKy7J1K1Zkti"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "\n",
        "class CheXpertDataset(Dataset):\n",
        "    def __init__(self, dataframe, class_names, zip_path, transform=None):\n",
        "        # Initialize the dataset with a dataframe, class names, zip path, and optional transform\n",
        "        self.dataframe = dataframe\n",
        "        self.class_names = class_names\n",
        "        self.transform = transform  # Use this later on to resize images and pre-process if needed\n",
        "\n",
        "    def __len__(self):\n",
        "        # Return the length of the dataframe, which is the number of samples in the dataset\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Get the image path from the dataframe at the given index\n",
        "        img_path = self.dataframe.iloc[idx]['path']\n",
        "        FOLDER = \"\"  # Define the folder path if needed\n",
        "        img_path = FOLDER + img_path\n",
        "        # Open the image and convert it to grayscale\n",
        "        image = Image.open(img_path).convert('L')\n",
        "        # Get the labels for the image from the dataframe and convert them to float32\n",
        "        labels = self.dataframe.iloc[idx][self.class_names].values.astype('float32')\n",
        "        # Convert the labels to a torch tensor\n",
        "        labels = torch.tensor(labels, dtype=torch.float32)\n",
        "\n",
        "        # Apply the transform to the image if provided\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        # Return the image and labels\n",
        "        return image, labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVNCU2Kpcyl1"
      },
      "source": [
        "# Models classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nw0vlqWmZktg"
      },
      "source": [
        "## Stacked model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "txLGdDoZZktg"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "class StackedModel(nn.Module):\n",
        "    def __init__(self, n_labels, freeze_layers):\n",
        "        super(StackedModel, self).__init__()\n",
        "        self.base_model1 = models.mobilenet_v2(pretrained=True)\n",
        "        self.base_model2 = models.densenet169(pretrained=True)\n",
        "\n",
        "        # Modify the first convolutional layer to accept 1-channel input for MobileNetV2\n",
        "        self.base_model1.features[0] = nn.Conv2d(1, 32, kernel_size=3, stride=2, padding=1, bias=False)\n",
        "\n",
        "        # Modify the first convolutional layer to accept 1-channel input for DenseNet169\n",
        "        self.base_model2.features.conv0 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "\n",
        "        if freeze_layers:\n",
        "            for param in self.base_model1.parameters():\n",
        "                param.requires_grad = False\n",
        "            for param in self.base_model2.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "\n",
        "        # # Ensure the modified first layers are not frozen\n",
        "        # self.base_model1.features[0][0].weight.requires_grad = True\n",
        "        # self.base_model2.features.conv0.weight.requires_grad = True\n",
        "\n",
        "        self.base_model1.classifier = nn.Identity()\n",
        "        self.base_model2.classifier = nn.Identity()\n",
        "\n",
        "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(1664 + 1280, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(128, n_labels),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.base_model1.features(x)\n",
        "        x1 = self.global_avg_pool(x1)\n",
        "        x1 = torch.flatten(x1, 1)\n",
        "\n",
        "        x2 = self.base_model2.features(x)\n",
        "        x2 = self.global_avg_pool(x2)\n",
        "        x2 = torch.flatten(x2, 1)\n",
        "\n",
        "        x = torch.cat((x1, x2), dim=1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "def upload_stacked_models(n_labels=1, freeze_layers=True):\n",
        "    \"\"\"\n",
        "    Create a stacked model using DenseNet169 and MobileNetV2 as base models.\n",
        "\n",
        "    Parameters:\n",
        "    - n_labels: Number of output labels (classes).\n",
        "    - freeze_layers: Boolean indicating whether to freeze the original layers.\n",
        "\n",
        "    Returns:\n",
        "    - The stacked model.\n",
        "    \"\"\"\n",
        "    model = StackedModel(n_labels, freeze_layers)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50Zd-3EfZkth"
      },
      "source": [
        "# Preprocessing utils functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PNrzHxVWZkth"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import zipfile\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Global preprocessing functions\n",
        "\n",
        "def prepare_dataset(dataframe, policy, class_names):\n",
        "    \"\"\"\n",
        "    Prepare the dataset by filtering, shuffling, and filling missing values.\n",
        "\n",
        "    Parameters:\n",
        "    - dataframe: The input DataFrame containing the dataset.\n",
        "    - policy: The policy to handle uncertain labels (-1). Options are \"ones\", \"zeroes\", \"mixed\".\n",
        "    - class_names: List of class names for the medical conditions.\n",
        "\n",
        "    Returns:\n",
        "    - x_path: Numpy array of image paths.\n",
        "    - y: Numpy array of labels corresponding to the class names.\n",
        "    \"\"\"\n",
        "    # Count the occurrences of each unique value in the \"Pleural Effusion\" column\n",
        "    pleural_effusion_counts = dataframe['Pleural Effusion'].value_counts()\n",
        "    print(f\"in dataframe Count for each class:\\n{pleural_effusion_counts}\")\n",
        "\n",
        "    # Filter the dataset to include only frontal images\n",
        "    dataset_df = dataframe[dataframe['Frontal/Lateral'] == 'Frontal']\n",
        "    dataset_df = dataset_df.dropna(subset=['Pleural Effusion'])\n",
        "\n",
        "    # Count the occurrences of each unique value in the \"Pleural Effusion\" column\n",
        "    pleural_effusion_counts = dataset_df['Pleural Effusion'].value_counts()\n",
        "    print(f\"in dataset_df (only Frontal) Count for each class:\\n{pleural_effusion_counts}\")\n",
        "\n",
        "    # Extract image paths and labels\n",
        "    x_path = dataset_df[\"Path\"].to_numpy()\n",
        "    y_df = dataset_df[class_names]\n",
        "\n",
        "    # Count the occurrences of each unique value in the labels DataFrame\n",
        "    pleural_effusion_counts = y_df.value_counts()\n",
        "    print(f\"in y_df Count for each class:\\n{pleural_effusion_counts}\")\n",
        "\n",
        "    # Define classes to be treated as ones in the \"mixed\" policy\n",
        "    class_ones = ['Atelectasis', 'Cardiomegaly']\n",
        "\n",
        "    # Initialize the labels array\n",
        "    y = np.empty(y_df.shape, dtype=int)\n",
        "\n",
        "    # Define a dictionary to map policies to their corresponding actions\n",
        "    policy_actions = {\n",
        "        \"ones\": lambda cls: 1,\n",
        "        \"zeroes\": lambda cls: 0,\n",
        "        \"mixed\": lambda cls: 1 if cls in class_ones else 0\n",
        "    }\n",
        "\n",
        "    # Iterate over each row in the labels DataFrame\n",
        "    for i, (index, row) in enumerate(y_df.iterrows()):\n",
        "        labels = []\n",
        "        for cls in class_names:\n",
        "            curr_val = row[cls]\n",
        "            if curr_val:\n",
        "                curr_val = float(curr_val)\n",
        "                if curr_val == 1:\n",
        "                    feat_val = 1\n",
        "                elif curr_val == -1:\n",
        "                    feat_val = policy_actions.get(policy, lambda cls: 0)(cls)\n",
        "                else:\n",
        "                    feat_val = 0\n",
        "            else:\n",
        "                feat_val = 0\n",
        "            labels.append(feat_val)\n",
        "        y[i] = labels\n",
        "\n",
        "    # Flatten the y array and convert to a pandas Series to get value counts\n",
        "    y_flattened = y.flatten()\n",
        "    y_series = pd.Series(y_flattened)\n",
        "    pleural_effusion_counts = y_series.value_counts()\n",
        "    print(f\"in y (labels) Count for each class:\\n{pleural_effusion_counts}\")\n",
        "\n",
        "    return x_path, y\n",
        "\n",
        "def split_train_val(train_df, policy, class_names, test_size=0.2, random_state=42):\n",
        "    \"\"\"\n",
        "    Split the training data into training and validation sets.\n",
        "\n",
        "    Parameters:\n",
        "    - train_df: DataFrame containing the training data.\n",
        "    - policy: The policy to handle uncertain labels (-1). Options are \"ones\", \"zeroes\", \"mixed\".\n",
        "    - class_names: List of class names for the medical conditions.\n",
        "    - test_size: Proportion of the training data to include in the validation set.\n",
        "    - random_state: Random seed for reproducibility.\n",
        "\n",
        "    Returns:\n",
        "    - train_df: DataFrame containing the training data.\n",
        "    - val_df: DataFrame containing the validation data.\n",
        "    \"\"\"\n",
        "    # Prepare the training dataset\n",
        "    train_paths, train_labels = prepare_dataset(train_df, policy, class_names)\n",
        "\n",
        "    # Split the training dataset into training and validation sets\n",
        "    train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
        "        train_paths, train_labels, test_size=test_size, random_state=random_state\n",
        "    )\n",
        "\n",
        "    # Create DataFrames for the training and validation sets\n",
        "    train_df = pd.DataFrame({'path': train_paths})\n",
        "    train_labels_df = pd.DataFrame(train_labels, columns=class_names)\n",
        "    train_df = pd.concat([train_df, train_labels_df], axis=1)\n",
        "\n",
        "    val_df = pd.DataFrame({'path': val_paths})\n",
        "    val_labels_df = pd.DataFrame(val_labels, columns=class_names)\n",
        "    val_df = pd.concat([val_df, val_labels_df], axis=1)\n",
        "\n",
        "    return train_df, val_df\n",
        "\n",
        "def prepare_test_dataset(valid_df, policy, class_names):\n",
        "    \"\"\"\n",
        "    Prepare the test dataset (original validation set).\n",
        "\n",
        "    Parameters:\n",
        "    - valid_df: DataFrame containing the original validation data.\n",
        "    - policy: The policy to handle uncertain labels (-1). Options are \"ones\", \"zeroes\", \"mixed\".\n",
        "    - class_names: List of class names for the medical conditions.\n",
        "\n",
        "    Returns:\n",
        "    - test_df: DataFrame containing the test data.\n",
        "    \"\"\"\n",
        "    # Prepare the test dataset\n",
        "    test_paths, test_labels = prepare_dataset(valid_df, policy, class_names)\n",
        "\n",
        "    # Create DataFrame for the test set\n",
        "    test_df = pd.DataFrame({'path': test_paths})\n",
        "    test_labels_df = pd.DataFrame(test_labels, columns=class_names)\n",
        "    test_df = pd.concat([test_df, test_labels_df], axis=1)\n",
        "\n",
        "    return test_df\n",
        "\n",
        "def get_datasets(zip_path='chexpert.zip'):\n",
        "    \"\"\"\n",
        "    Get the training, validation, and test datasets.\n",
        "\n",
        "    Parameters:\n",
        "    - zip_path: Path to the zip file containing the dataset.\n",
        "\n",
        "    Returns:\n",
        "    - train_df: DataFrame containing the training data.\n",
        "    - validation_df: DataFrame containing the validation data.\n",
        "    - test_df: DataFrame containing the test data.\n",
        "    \"\"\"\n",
        "    # Read the training and validation data from the zip file\n",
        "    original_train_df, test_df = read_zip(zip_path=zip_path)\n",
        "\n",
        "    # Count the occurrences of each unique value in the \"Pleural Effusion\" column\n",
        "    pleural_effusion_counts = original_train_df['Pleural Effusion'].value_counts()\n",
        "    print(f\"in original_train_df Count for each class:\\n{pleural_effusion_counts}\")\n",
        "\n",
        "    policies = get_policies()\n",
        "    class_names = get_class_names()\n",
        "\n",
        "    # Select the policy to handle uncertain labels (-1)\n",
        "    selected_policy = policies[0]\n",
        "\n",
        "    # Split the original training data into separate training and validation sets\n",
        "    train_df, validation_df = split_train_val(original_train_df, selected_policy, class_names)\n",
        "\n",
        "    # Prepare the test dataset\n",
        "    test_df = prepare_test_dataset(test_df, selected_policy, class_names)\n",
        "\n",
        "    return train_df, validation_df, test_df\n",
        "\n",
        "def read_zip(zip_path='chexpert.zip'):\n",
        "    \"\"\"\n",
        "    Read training and validation data from a zip file.\n",
        "\n",
        "    Parameters:\n",
        "    - zip_path: Path to the zip file containing the dataset.\n",
        "\n",
        "    Returns:\n",
        "    - original_train_df: DataFrame containing the original training data.\n",
        "    - test_df: DataFrame containing the original validation data.\n",
        "    \"\"\"\n",
        "    original_train_df, test_df = None, None\n",
        "\n",
        "    # Read CSV files from the zip file\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        with zip_ref.open('train.csv') as train_file:\n",
        "            original_train_df = pd.read_csv(train_file)\n",
        "        with zip_ref.open('valid.csv') as valid_file:\n",
        "            test_df = pd.read_csv(valid_file)\n",
        "\n",
        "    return original_train_df, test_df\n",
        "\n",
        "def get_transform(augment=False):\n",
        "    \"\"\"\n",
        "    Define the transformation pipeline for the images.\n",
        "\n",
        "    Parameters:\n",
        "    - augment: Whether to apply data augmentation.\n",
        "\n",
        "    Returns:\n",
        "    - transform: Composed transformation pipeline.\n",
        "    \"\"\"\n",
        "    transform_list = [\n",
        "        transforms.Resize((224, 224)),  # Resize images to 224x224 pixels\n",
        "        transforms.ToTensor(),          # Convert images to PyTorch tensors\n",
        "        transforms.Normalize(mean=[0.5], std=[0.5])  # Normalize grayscale images\n",
        "    ]\n",
        "\n",
        "    if augment:\n",
        "        # Add data augmentation transformations to help with generalization\n",
        "        augmentations = [\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.RandomRotation(10),\n",
        "            transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
        "            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
        "            transforms.RandomVerticalFlip(),\n",
        "            transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
        "            transforms.RandomPerspective(distortion_scale=0.2, p=0.5),\n",
        "            transforms.ElasticTransform(alpha=30.0, sigma=5.0)\n",
        "        ]\n",
        "        transform_list = augmentations + transform_list\n",
        "\n",
        "    transform = transforms.Compose(transform_list)\n",
        "    return transform\n",
        "\n",
        "def transform_dataset(df, zip_path='chexpert.zip', batch_size=16, shuffle=True, augment=False):\n",
        "    \"\"\"\n",
        "    Transform the dataset into DataLoader objects for given dataframe.\n",
        "\n",
        "    Parameters:\n",
        "    - df: DataFrame containing the dataset.\n",
        "    - zip_path: Path to the zip file containing the images.\n",
        "    - batch_size: Number of samples in each batch.\n",
        "    - shuffle: Whether to shuffle the data.\n",
        "    - augment: Whether to apply data augmentation.\n",
        "\n",
        "    Returns:\n",
        "    - dataset: CheXpertDataset object containing the dataset.\n",
        "    - loader: DataLoader object containing the dataset.\n",
        "    - images: Batch of images from the DataLoader.\n",
        "    - labels: Batch of labels from the DataLoader.\n",
        "    \"\"\"\n",
        "    # Define the class names for the medical conditions\n",
        "    class_names = get_class_names()\n",
        "\n",
        "    # Get the transformation pipeline\n",
        "    transformer = get_transform(augment=augment)\n",
        "\n",
        "    # Create the dataset with the defined transformations\n",
        "    dataset = CheXpertDataset(dataframe=df, class_names=class_names, zip_path=zip_path, transform=transformer)\n",
        "\n",
        "    # Create DataLoader for the dataset\n",
        "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, num_workers=4, pin_memory=True)\n",
        "\n",
        "    # Verify data loading by fetching a batch of images and labels from the DataLoader\n",
        "    images, labels = next(iter(loader))\n",
        "\n",
        "    return dataset, loader, images, labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wk1tFM26Zkte"
      },
      "source": [
        "# Train model functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmhU4UkTwLT5",
        "outputId": "fe45ebec-5ab2-4efc-cee7-5634961ab424"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Check if the folder exists\n",
        "if not os.path.exists('finetuned_models'):\n",
        "  # Create the folder if it doesn't exist\n",
        "  os.makedirs('finetuned_models')\n",
        "  print(\"Folder 'finetuned_models' created successfully.\")\n",
        "else:\n",
        "  print(\"Folder 'finetuned_models' already exists.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vPkQL11wZktf"
      },
      "outputs": [],
      "source": [
        "## Helper functions for training PyTorch models.\n",
        "\n",
        "import os\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "from tqdm.notebook import tqdm\n",
        "import numpy as np\n",
        "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "import torch.amp as amp  # Import the new amp module\n",
        "\n",
        "def train_model(model, train_loader: DataLoader, test_loader: DataLoader, criterion, optimizer, scheduler, num_epochs=5, model_name='model', device='cuda', patience=5, num_workers=2):\n",
        "    \"\"\"\n",
        "    Train a PyTorch model with the given parameters.\n",
        "\n",
        "    Parameters:\n",
        "    - model: The PyTorch model to be trained.\n",
        "    - train_loader: DataLoader for the training dataset.\n",
        "    - test_loader: DataLoader for the validation dataset.\n",
        "    - criterion: The loss function.\n",
        "    - optimizer: The optimizer.\n",
        "    - scheduler: The learning rate scheduler.\n",
        "    - num_epochs: Number of epochs to train the model.\n",
        "    - model_name: Name to save the trained model.\n",
        "    - device: Device to train the model on ('cpu' or 'cuda').\n",
        "    - patience: Number of epochs to wait for improvement before stopping early.\n",
        "    - num_workers: Number of worker processes for data loading.\n",
        "\n",
        "    Returns:\n",
        "    - train_losses: List of training losses for each epoch.\n",
        "    - train_accuracies: List of training accuracies for each epoch.\n",
        "    - test_losses: List of validation losses for each epoch.\n",
        "    - test_accuracies: List of validation accuracies for each epoch.\n",
        "    - test_aucs: List of validation AUCs for each epoch.\n",
        "    \"\"\"\n",
        "    model.to(device)\n",
        "\n",
        "    scaler = amp.GradScaler(device=device)  # Initialize the GradScaler for mixed precision training\n",
        "    save_path = f\"finetuned_models/{model_name}.pkl\"\n",
        "\n",
        "    train_losses = []\n",
        "    train_accuracies = []\n",
        "    test_losses = []\n",
        "    test_accuracies = []\n",
        "    test_aucs = []\n",
        "\n",
        "    best_loss = float('inf')\n",
        "    epochs_no_improve = 0\n",
        "\n",
        "    print(f\"Training {model_name} model for {num_epochs} epochs\")\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_train = 0\n",
        "        correct_train = 0\n",
        "        train_loss = 0.0\n",
        "\n",
        "        # Add a progress bar for the training loop\n",
        "        with tqdm(total=len(train_loader), desc=f\"Epoch {epoch+1}/{num_epochs} - Training\", unit=\"batch\") as pbar:\n",
        "            for inputs, labels in train_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                with amp.autocast(device_type=\"cuda\"):  # Use autocast for mixed precision training\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                scaler.scale(loss).backward()  # Scale the loss for mixed precision training\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "\n",
        "                # Accuracy and loss calculation\n",
        "                predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
        "                # Calculate accuracy per sample (averaged over labels)\n",
        "                correct_train += (predicted == labels).sum().item() / labels.size(1)\n",
        "                total_train += labels.size(0)\n",
        "                train_loss += loss.item()\n",
        "\n",
        "                pbar.update(1)\n",
        "\n",
        "        # Store the average metrics for this epoch\n",
        "        train_accuracy = correct_train / total_train\n",
        "        train_losses.append(train_loss / len(train_loader))\n",
        "        train_accuracies.append(train_accuracy)\n",
        "\n",
        "        # Evaluation phase (Test set)\n",
        "        model.eval()\n",
        "        correct_test = 0\n",
        "        total_test = 0\n",
        "        test_loss = 0.0\n",
        "        all_labels = []\n",
        "        all_outputs = []\n",
        "\n",
        "        with tqdm(total=len(test_loader), desc=f\"Epoch {epoch+1}/{num_epochs} - Evaluation\", unit=\"batch\") as pbar:\n",
        "            with torch.no_grad():\n",
        "                for inputs, labels in test_loader:\n",
        "                    inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "                    outputs = model(inputs)\n",
        "                    predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
        "                    total_test += labels.size(0)\n",
        "                    correct_test += (predicted == labels).sum().item() / labels.size(1)\n",
        "                    test_loss += criterion(outputs, labels).item()\n",
        "\n",
        "                    all_labels.append(labels.cpu().numpy())\n",
        "                    all_outputs.append(outputs.cpu().numpy())\n",
        "\n",
        "                    pbar.update(1)\n",
        "\n",
        "        test_accuracy = correct_test / total_test\n",
        "        test_losses.append(test_loss / len(test_loader))\n",
        "        test_accuracies.append(test_accuracy)\n",
        "\n",
        "        # Calculate AUC\n",
        "        all_labels = np.concatenate(all_labels)\n",
        "        all_outputs = np.concatenate(all_outputs)\n",
        "        test_auc = roc_auc_score(all_labels, all_outputs)\n",
        "        test_aucs.append(test_auc)\n",
        "\n",
        "        # Print the results for this epoch\n",
        "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_losses[-1]:.4f}, Train Accuracy: {train_accuracies[-1]:.4f}, Test Loss: {test_losses[-1]:.4f}, Test Accuracy: {test_accuracies[-1]:.4f}, Test AUC: {test_aucs[-1]:.4f}\")\n",
        "\n",
        "        # Plot ROC curve\n",
        "        fpr, tpr, _ = roc_curve(all_labels, all_outputs)\n",
        "        plt.figure()\n",
        "        plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {test_auc:.2f})')\n",
        "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "        plt.xlim([0.0, 1.0])\n",
        "        plt.ylim([0.0, 1.05])\n",
        "        plt.xlabel('False Positive Rate')\n",
        "        plt.ylabel('True Positive Rate')\n",
        "        plt.title(f'Receiver Operating Characteristic - Epoch {epoch + 1}')\n",
        "        plt.legend(loc=\"lower right\")\n",
        "        plt.show()\n",
        "\n",
        "        # Early stopping\n",
        "        if test_loss < best_loss:\n",
        "            best_loss = test_loss\n",
        "            epochs_no_improve = 0\n",
        "            torch.save(model.state_dict(), save_path)\n",
        "            print(f\"Saved new best model for epoch {epoch + 1} for model {model_name}\")\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            if epochs_no_improve >= patience:\n",
        "                print(f\"Early stopping at epoch {epoch + 1} for model {model_name}\")\n",
        "                break\n",
        "\n",
        "        # Adjust the learning rate based on the validation loss\n",
        "        scheduler.step(test_loss)\n",
        "\n",
        "    save_model(model, model_name=model_name, device=device)\n",
        "\n",
        "    return train_losses, train_accuracies, test_losses, test_accuracies, test_aucs\n",
        "\n",
        "def upload_pretrained_densenet169(pretrained_model, add_layers=True, n_labels=1, freeze_layers=True, unfreeze_modules=['features.denseblock4']):\n",
        "    \"\"\"\n",
        "    Modify a pre-trained DenseNet169 model by adding custom layers and optionally freezing the original layers.\n",
        "\n",
        "    Parameters:\n",
        "    - pretrained_model: The pre-trained model to be modified.\n",
        "    - add_layers: Boolean indicating whether to add custom layers.\n",
        "    - n_labels: Number of output labels (classes).\n",
        "    - freeze_layers: Boolean indicating whether to freeze the original layers.\n",
        "    - unfreeze_modules: List of layer names or indices to unfreeze (e.g., 'features.denseblock4').\n",
        "\n",
        "    Returns:\n",
        "    - The modified model.\n",
        "    \"\"\"\n",
        "    # Step 1: Freeze all layers\n",
        "    if freeze_layers:\n",
        "        for param in pretrained_model.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "    # Step 2: Unfreeze specific layers (if specified)\n",
        "    if unfreeze_modules:\n",
        "        for name, child in pretrained_model.named_modules():\n",
        "            if any(layer_name in name for layer_name in unfreeze_modules):\n",
        "                for param in child.parameters():\n",
        "                    param.requires_grad = True\n",
        "\n",
        "    # Step 3: Modify the first convolutional layer to accept 1-channel input for DenseNet169\n",
        "    pretrained_model.features.conv0 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "\n",
        "    # Step 4: Add custom layers if specified\n",
        "    if add_layers:\n",
        "        in_features = pretrained_model.classifier.in_features\n",
        "        pretrained_model.classifier = nn.Sequential(\n",
        "            nn.Linear(in_features, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(64, n_labels)\n",
        "        )\n",
        "\n",
        "    return pretrained_model\n",
        "\n",
        "def upload_pretrained_vit(vit_model, add_layers=True, n_labels=5, freeze_layers=True):\n",
        "    \"\"\"\n",
        "    Modify a pre-trained Vision Transformer (ViT) model by adding custom layers and optionally freezing the original layers.\n",
        "\n",
        "    Parameters:\n",
        "    - vit_model: The pre-trained ViT model to be modified.\n",
        "    - add_layers: Boolean indicating whether to add custom layers.\n",
        "    - n_labels: Number of output labels (classes).\n",
        "    - freeze_layers: Boolean indicating whether to freeze the original layers.\n",
        "\n",
        "    Returns:\n",
        "    - The modified ViT model.\n",
        "    \"\"\"\n",
        "    if freeze_layers:\n",
        "        for param in vit_model.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "    if add_layers:\n",
        "        # Access the first module inside the Sequential container to get in_features\n",
        "        if isinstance(vit_model.heads, nn.Sequential):\n",
        "            in_features = vit_model.heads[0].in_features\n",
        "        else:\n",
        "            in_features = vit_model.heads.in_features\n",
        "\n",
        "        vit_model.heads = nn.Sequential(\n",
        "            nn.Linear(in_features, 16),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(16, n_labels)\n",
        "        )\n",
        "\n",
        "    return vit_model\n",
        "\n",
        "def upload_pretrained_densenet121(pretrained_model, add_layers=True, n_labels=1, freeze_layers=True):\n",
        "    \"\"\"\n",
        "    Modify a pre-trained DenseNet121 model by adding custom layers and optionally freezing the original layers.\n",
        "\n",
        "    Parameters:\n",
        "    - pretrained_model: The pre-trained model to be modified.\n",
        "    - add_layers: Boolean indicating whether to add custom layers.\n",
        "    - n_labels: Number of output labels (classes).\n",
        "    - freeze_layers: Boolean indicating whether to freeze the original layers.\n",
        "\n",
        "    Returns:\n",
        "    - The modified model.\n",
        "    \"\"\"\n",
        "    if freeze_layers:\n",
        "        for param in pretrained_model.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "    if add_layers:\n",
        "        in_features = pretrained_model.classifier.in_features\n",
        "        pretrained_model.classifier = nn.Sequential(\n",
        "            nn.Linear(in_features, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.Linear(32, n_labels)\n",
        "        )\n",
        "\n",
        "    return pretrained_model\n",
        "\n",
        "def upload_stacked_models(n_labels=1, freeze_layers=True):\n",
        "    \"\"\"\n",
        "    Create a stacked model using DenseNet169 and MobileNetV2 as base models.\n",
        "\n",
        "    Parameters:\n",
        "    - n_labels: Number of output labels (classes).\n",
        "    - freeze_layers: Boolean indicating whether to freeze the original layers.\n",
        "\n",
        "    Returns:\n",
        "    - The stacked model.\n",
        "    \"\"\"\n",
        "    class StackedModel(nn.Module):\n",
        "        def __init__(self, n_labels, freeze_layers):\n",
        "            super(StackedModel, self).__init__()\n",
        "            self.base_model1 = models.densenet169(pretrained=True)\n",
        "            self.base_model2 = models.mobilenet_v2(pretrained=True)\n",
        "\n",
        "            if freeze_layers:\n",
        "                for param in self.base_model1.parameters():\n",
        "                    param.requires_grad = False\n",
        "                for param in self.base_model2.parameters():\n",
        "                    param.requires_grad = False\n",
        "\n",
        "            self.base_model1.classifier = nn.Identity()\n",
        "            self.base_model2.classifier = nn.Identity()\n",
        "\n",
        "            self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "            self.fc = nn.Sequential(\n",
        "                nn.Linear(1664 + 1280, 512),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(0.5),\n",
        "                nn.Linear(512, 256),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(0.5),\n",
        "                nn.Linear(256, 128),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(0.5),\n",
        "                nn.Linear(128, n_labels),\n",
        "                nn.Sigmoid()\n",
        "            )\n",
        "\n",
        "        def forward(self, x):\n",
        "            x1 = self.base_model1.features(x)\n",
        "            x1 = self.global_avg_pool(x1)\n",
        "            x1 = torch.flatten(x1, 1)\n",
        "\n",
        "            x2 = self.base_model2.features(x)\n",
        "            x2 = self.global_avg_pool(x2)\n",
        "            x2 = torch.flatten(x2, 1)\n",
        "\n",
        "            x = torch.cat((x1, x2), dim=1)\n",
        "            x = self.fc(x)\n",
        "            return x\n",
        "\n",
        "    model = StackedModel(n_labels, freeze_layers)\n",
        "    return model\n",
        "\n",
        "def save_model(model, model_name, device='cuda'):\n",
        "    \"\"\"\n",
        "    Save a PyTorch model to a file using pickle and ONNX.\n",
        "\n",
        "    Parameters:\n",
        "    - model: The PyTorch model to be saved.\n",
        "    - model_name: The name of the model to save.\n",
        "    - device: Device to save the model on ('cpu' or 'cuda').\n",
        "    \"\"\"\n",
        "    pickle_path = f\"finetuned_models/{model_name}.pkl\"\n",
        "    print(f\"Model pickled saved in {pickle_path}\")\n",
        "    torch.save(model, pickle_path)\n",
        "\n",
        "    pth_path = f\"finetuned_models/{model_name}.pth\"\n",
        "    print(f\"Model pth saved in {pth_path}\")\n",
        "    torch.save(model.state_dict(), pth_path)\n",
        "\n",
        "    # Define dummy input for ONNX export (batch size 1, 1 channel, 224x224 image size)\n",
        "    dummy_input = torch.randn(1, 1, 224, 224).to(device)\n",
        "\n",
        "    # Export the model to ONNX format\n",
        "    onnx_path = f\"finetuned_models/{model_name}.onnx\"\n",
        "    torch.onnx.export(model, dummy_input, onnx_path,\n",
        "                      input_names=[\"input\"],\n",
        "                      output_names=[\"output\"],\n",
        "                      opset_version=11)\n",
        "\n",
        "    print(f\"Model saved as onnx in {onnx_path}\")\n",
        "\n",
        "def load_model(filename, device='cuda'):\n",
        "    \"\"\"\n",
        "    Load a PyTorch model from a file.\n",
        "\n",
        "    Parameters:\n",
        "    - filename: The name of the file to load the model from.\n",
        "    - device: Device to load the model on ('cpu' or 'cuda').\n",
        "\n",
        "    Returns:\n",
        "    - The loaded PyTorch model.\n",
        "    \"\"\"\n",
        "    path = f\"finetuned_models/{filename}\"\n",
        "    loaded_model = torch.load(path, map_location=device)\n",
        "    return loaded_model\n",
        "\n",
        "def predict_model(model, loader, device='cuda'):\n",
        "    \"\"\"\n",
        "    Predict using a trained PyTorch model.\n",
        "\n",
        "    Parameters:\n",
        "    - model: The trained PyTorch model.\n",
        "    - loader: DataLoader for the dataset to predict on.\n",
        "    - device: Device to run the predictions on ('cpu' or 'cuda').\n",
        "\n",
        "    Returns:\n",
        "    - predictions: Numpy array of predictions.\n",
        "    - labels: Numpy array of true labels.\n",
        "    \"\"\"\n",
        "    model.to(device)\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            preds = torch.sigmoid(outputs).cpu().numpy()\n",
        "            all_preds.extend(preds)\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    return np.array(all_preds), np.array(all_labels)\n",
        "\n",
        "def plot_roc_curve(labels, preds, model_name):\n",
        "    \"\"\"\n",
        "    Plot the ROC curve for the given model.\n",
        "\n",
        "    Parameters:\n",
        "    - labels: Numpy array of true labels.\n",
        "    - preds: Numpy array of predicted probabilities.\n",
        "    - model_name: Name of the model.\n",
        "\n",
        "    Returns:\n",
        "    - None\n",
        "    \"\"\"\n",
        "    class_names = get_class_names()\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    for i, class_name in enumerate(class_names):\n",
        "        fpr, tpr, _ = roc_curve(labels[:, i], preds[:, i])\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        plt.plot(fpr, tpr, lw=2, label=f'{class_name} (AUC = {roc_auc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'ROC Curve for model {model_name}')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.grid()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXHYtcZRZkti"
      },
      "source": [
        "### Download dataset from Kaggle or Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24BC61sMoWgx",
        "outputId": "25b60043-ff93-4c8f-8153-deb6cd31713e"
      },
      "outputs": [],
      "source": [
        "if is_colab():\n",
        "  from google.colab import drive\n",
        "  # Mount Google Drive\n",
        "  drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9EyNsX76Zkti",
        "outputId": "36cfaf88-9224-4422-e33e-9c4e9b08a7cd"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import subprocess\n",
        "\n",
        "# Check if Google Drive is mounted and the zip file exists\n",
        "drive_mounted = os.path.exists('/content/drive')\n",
        "zip_in_drive = os.path.exists(zip_file_in_drive)\n",
        "\n",
        "# Check if the dataset is already downloaded locally, if not download it\n",
        "print(f\"Checking if dataset zip file exists at {zip_path}\")\n",
        "if not os.path.exists(zip_path):\n",
        "    # Use the zip file from Google Drive if available, otherwise download\n",
        "    print(\"Dataset zip file not found locally, searching in drive if connected.\")\n",
        "    if drive_mounted and zip_in_drive:\n",
        "        print(\"Using dataset from Google Drive.\")\n",
        "        zip_path = zip_file_in_drive  # Update zip_path to use the Drive location\n",
        "    else:\n",
        "        print(\"Downloading the dataset...\")\n",
        "        # Check if kaggle is installed\n",
        "        try:\n",
        "            subprocess.run([\"kaggle\", \"--version\"], check=True)\n",
        "            print(\"Kaggle is already installed.\")\n",
        "        except subprocess.CalledProcessError:\n",
        "            print(\"Kaggle is not installed. Installing kaggle...\")\n",
        "            %pip install kaggle\n",
        "\n",
        "        # Check if the kaggle.json file exists in the destination\n",
        "        kaggle_json_path = os.path.expanduser('~/.kaggle/kaggle.json')\n",
        "        if not os.path.exists('kaggle.json') and not os.path.exists(kaggle_json_path):\n",
        "            # Move kaggle.json to ~/.kaggle\n",
        "            os.makedirs(os.path.dirname(kaggle_json_path), exist_ok=True)\n",
        "            shutil.move('kaggle.json', kaggle_json_path)\n",
        "            # Set permissions\n",
        "            os.chmod(kaggle_json_path, 0o600)\n",
        "        else:\n",
        "            print(\"kaggle.json already exists in the destination.\")\n",
        "\n",
        "        # Download the dataset from Kaggle\n",
        "        subprocess.run([\"kaggle\", \"datasets\", \"download\", \"-d\", \"ashery/chexpert\"], check=True)\n",
        "        print(\"Dataset was downloaded from Kaggle.\")\n",
        "\n",
        "        if drive_mounted:\n",
        "            print(\"Saving dataset to Google Drive for future use.\")\n",
        "            shutil.copy(zip_path, zip_file_in_drive)\n",
        "            print(f\"Dataset saved to {zip_file_in_drive}\")\n",
        "\n",
        "else:\n",
        "    print(\"Dataset already downloaded.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lW77uv8wZktj"
      },
      "source": [
        "### Extract the zip file to improve performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jFuEYDVZktj",
        "outputId": "6e0fdda8-2a90-4c5b-c414-abc5ab1e9240"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "\n",
        "# Check if the dataset is already extracted, if not extract it\n",
        "if not os.path.exists(data_dir):\n",
        "    print(\"Extracting the dataset...\")\n",
        "    #unzip\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(data_dir)\n",
        "    #list files in the extracted dir\n",
        "    os.listdir(data_dir)\n",
        "else:\n",
        "    print(\"Dataset already extracted.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOEL7OWPmpax"
      },
      "source": [
        "## Save zip to google drive if you want to save time next time running this notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1V84OEaDZktj"
      },
      "source": [
        "### Load train, validtion and test datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0j8iHEIYZktj",
        "outputId": "86429877-d4df-42cc-86eb-edcd930d3850"
      },
      "outputs": [],
      "source": [
        "# Load the datasets\n",
        "train_df, validation_df, test_df = get_datasets(zip_path)\n",
        "\n",
        "if train_df is None or validation_df is None or test_df is None:\n",
        "    print(\"Error loading the datasets.\")\n",
        "else:\n",
        "    print(\"Datasets loaded successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtsDpprnZktj"
      },
      "source": [
        "#### Peak into training dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        },
        "id": "E0wtwfqZZktj",
        "outputId": "cb6e8493-f087-412b-ca27-c071fd0c4e2d"
      },
      "outputs": [],
      "source": [
        "# Print some information about the train DataFrame\n",
        "display(train_df.head())\n",
        "print(\"Number of rows and columns in the train DataFrame:\", train_df.shape)\n",
        "# Print the column names and their data types\n",
        "print(\"Column names and data types:\")\n",
        "print(train_df.dtypes)\n",
        "\n",
        "# Count the occurrences of each unique value in the \"Pleural Effusion\" column\n",
        "pleural_effusion_counts = train_df['Pleural Effusion'].value_counts()\n",
        "\n",
        "# Print the counts for each class\n",
        "print(f\"Count for each class:\\n{pleural_effusion_counts}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOShKThaZktj"
      },
      "source": [
        "### Peak into the validation dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        },
        "id": "e8UT_9_jZktj",
        "outputId": "a7cf6efd-eb86-4a6e-c36e-6d47193f2dee"
      },
      "outputs": [],
      "source": [
        "# Print some information about the validtion DataFrame\n",
        "# Set pandas display options to show all columns\n",
        "display(validation_df.head())\n",
        "print(\"Number of rows and columns in the validation DataFrame:\", validation_df.shape)\n",
        "# Print the column names and their data types\n",
        "print(\"Column names and data types:\")\n",
        "print(validation_df.dtypes)\n",
        "\n",
        "# Count the occurrences of each unique value in the \"Pleural Effusion\" column\n",
        "pleural_effusion_counts = validation_df['Pleural Effusion'].value_counts()\n",
        "\n",
        "# Print the counts for each class\n",
        "print(f\"Count for each class:\\n{pleural_effusion_counts}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lgbXrzEZktk"
      },
      "source": [
        "#### Peak into the test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        },
        "id": "bJM7wsccZktk",
        "outputId": "656082d6-21ad-4645-da98-09e55e2dc049"
      },
      "outputs": [],
      "source": [
        "# Print some information about the train DataFrame\n",
        "# Set pandas display options to show all columns\n",
        "display(test_df.head())\n",
        "print(\"Number of rows and columns in the test DataFrame:\", test_df.shape)\n",
        "# Print the column names and their data types\n",
        "print(\"Column names and data types:\")\n",
        "print(test_df.dtypes)\n",
        "\n",
        "\n",
        "# Count the occurrences of each unique value in the \"Pleural Effusion\" column\n",
        "pleural_effusion_counts = test_df['Pleural Effusion'].value_counts()\n",
        "\n",
        "# Print the counts for each class\n",
        "print(f\"Count for each class:\\n{pleural_effusion_counts}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4wvmhRiZktk"
      },
      "source": [
        "#### Dataset formation according to torch (using dataloaders)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ik0iyiuFZktk"
      },
      "outputs": [],
      "source": [
        "# Transform the training dataset\n",
        "train_dataset, train_loader, train_images, train_labels = transform_dataset(train_df, zip_path, batch_size=batch_size, shuffle=True, augment=True)\n",
        "\n",
        "# Transform the validation dataset\n",
        "validtion_dataset, validtion_loader, validtion_images, validtion_labels = transform_dataset(validation_df, zip_path, batch_size=batch_size, shuffle=False, augment=False)\n",
        "\n",
        "# Transform the test dataset\n",
        "test_dataset, test_loader, test_images, test_labels = transform_dataset(test_df, zip_path, batch_size=batch_size, shuffle=False, augment=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NvnyktjZktk"
      },
      "source": [
        "#### Visualising example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "C5fXPwCaZktk",
        "outputId": "bd99a914-19f2-4da4-e0f6-4c8f828313d7"
      },
      "outputs": [],
      "source": [
        "# Select the first image in the batch\n",
        "image = test_images[0]\n",
        "original_shape = image.shape\n",
        "image = image.permute(1, 2, 0).numpy()  # Change shape to (224, 224)\n",
        "new_shape = image.shape\n",
        "print(f\"Original shape: {original_shape}, New shape: {new_shape}\")\n",
        "# Check the shape of the image to ensure it is (224, 224, 3)\n",
        "assert new_shape == (224, 224, 1), f\"Expected shape (224, 224), but got {image.shape}\"\n",
        "\n",
        "# Denormalize the image for visualization\n",
        "image = (image * 0.5) + 0.5\n",
        "\n",
        "# Plot the image\n",
        "print(\"Example image:\")\n",
        "plt.imshow(image)\n",
        "plt.axis('off')  # Hide axes\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIb84t1EZktk"
      },
      "source": [
        "#### Here we can extract different pre-trained models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlLxFJkXfWKz"
      },
      "source": [
        "# Choose model to train, execute only the one you wish to train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fc5KjpnYZktk"
      },
      "source": [
        "### Train Stacked Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GXbTxXjCZktl"
      },
      "outputs": [],
      "source": [
        "from StackedModel import upload_stacked_models\n",
        "\n",
        "model = upload_stacked_models(n_labels=len(class_names), freeze_layers=True)\n",
        "\n",
        "# Move the model to the appropriate device\n",
        "model.to(device)\n",
        "\n",
        "model_name = \"stacked_model\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_RaLutnZktl"
      },
      "source": [
        "### Train Densenet169"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2arRaD0BZktl"
      },
      "outputs": [],
      "source": [
        "# Load a pre-trained DenseNet169 model, add custom layers, and freeze certain layers\n",
        "#\n",
        "# Parameters:\n",
        "# - pretrained: Use a pre-trained version of DenseNet169\n",
        "# - add_layers: Add custom layers to the model\n",
        "# - n_labels: Number of output labels (classes)\n",
        "# - freeze_layers: Freeze the layers of the pre-trained model to prevent them from being updated during training\n",
        "\n",
        "# Load the pre-trained DenseNet169 model with ImageNet weights\n",
        "denseNet169 = models.densenet169(weights=models.DenseNet169_Weights.IMAGENET1K_V1)\n",
        "\n",
        "# Modify the DenseNet169 model by adding custom layers and freezing certain layers\n",
        "model = upload_pretrained_densenet169(denseNet169, add_layers=True, n_labels=len(class_names), freeze_layers=True)\n",
        "\n",
        "# Move the model to the appropriate device (e.g., 'cuda' for GPU or 'cpu' for CPU)\n",
        "model.to(device)\n",
        "\n",
        "# Define the model name for saving purposes\n",
        "model_name = \"densenet169\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sfbu8a9JZktl"
      },
      "source": [
        "#### Summary of Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkyB9pmSZktl",
        "outputId": "f28e2186-0879-49db-a552-058f794a6f5b"
      },
      "outputs": [],
      "source": [
        "# Display the model summary, input size (1 channel, 224x224 image)\n",
        "summary(model, input_size=(1, 224, 224)) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNlzIN7-Zktl"
      },
      "source": [
        "#### Here is how we train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 768,
          "referenced_widgets": [
            "bb841543dea049cb97f93cc2ededba56",
            "8dc527440c604ac8a1d95313e796d5e3",
            "3f4c99b5d69c4dd4a10ecbf90fe308c0",
            "b5e61be1e8e746baa0e4068b9622ce37",
            "5be23f3309134bb0bfb42dd7b865df04",
            "4a042298959142c7b8a2f9a4bc83bb1c",
            "f083ef8e478c4e959bdc7f642a7d452a",
            "eb9920d613d54a7ca2a36e49eec3c6dd",
            "140aa71728334ef1b1742a37d20162ed",
            "782a80b6290d47af9ba652ec2265234b",
            "702ee58fe2fd4f83882e4e7ad22a436e",
            "049a759464ff4a41bfeaf92e476d501d",
            "b0f02c1151b04c90b5ec62790893c1fa",
            "3781a490ec5e4020a9d45e139b1b2348",
            "dec47e76c2774ed0bddfb6a4be0bbc0f",
            "a628d67cbf5948a680509e236f6aa364",
            "4d167bd3c4424097a740baac320f209e",
            "e3e9d700db1b4272a16eca6b3efb9e40",
            "7eb2e1c5b9d34f059418da50cacd37cd",
            "106921c8222d4618a3a3ffb22f24a4bc",
            "c764873684fc41d7948fdeee9d747220",
            "f522c8effb784e9f8c1629d2c8507788"
          ]
        },
        "id": "ZAlb7_OsZktl",
        "outputId": "538a3760-b3b9-494c-c7d2-85dee9aee4d2"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "# Calculate class weights to handle class imbalance\n",
        "# The weight for the positive class (Pleural Effusion = 1) is calculated as:\n",
        "# total number of samples / (2 * number of positive samples)\n",
        "# This ensures that the positive class is given more importance during training.\n",
        "class_weights = torch.tensor([1.0, len(train_df['Pleural Effusion']) / (2 * sum(train_df['Pleural Effusion']))], dtype=torch.float32)\n",
        "\n",
        "# Define the loss function with class weights\n",
        "# BCEWithLogitsLoss combines a Sigmoid layer and the BCELoss in one single class\n",
        "criterion = nn.BCEWithLogitsLoss(pos_weight=class_weights[1])\n",
        "\n",
        "# Define the optimizer with weight decay\n",
        "# AdamW optimizer with a learning rate of 0.001 and weight decay of 1e-5\n",
        "optimizer_densenet = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
        "\n",
        "# Define a learning rate scheduler\n",
        "# ReduceLROnPlateau reduces the learning rate when a metric has stopped improving\n",
        "scheduler = ReduceLROnPlateau(optimizer_densenet, mode='min', factor=0.1, patience=5)\n",
        "\n",
        "# Define the number of epochs\n",
        "num_epochs = 1\n",
        "\n",
        "# Train the model\n",
        "# Parameters:\n",
        "# - model: The model to be trained (DenseNet169 in this case)\n",
        "# - train_loader: DataLoader for the training dataset\n",
        "# - test_loader: DataLoader for the validation dataset\n",
        "# - criterion: The loss function\n",
        "# - optimizer: The optimizer\n",
        "# - scheduler: The learning rate scheduler\n",
        "# - num_epochs: Number of epochs to train the model\n",
        "# - device: Device to train the model on ('cpu' or 'cuda')\n",
        "# - model_name: Filename to save the trained model\n",
        "# - num_workers: Number of worker processes for data loading\n",
        "train_losses, train_accuracies, test_losses, test_accuracies, test_aucs = train_model(\n",
        "    model=model,\n",
        "    train_loader=train_loader,\n",
        "    test_loader=validtion_loader,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer_densenet,\n",
        "    scheduler=scheduler,\n",
        "    num_epochs=num_epochs,\n",
        "    device=device,\n",
        "    model_name=model_name,\n",
        "    num_workers=2\n",
        ")\n",
        "\n",
        "# Adjust the learning rate based on the validation loss\n",
        "for epoch in range(num_epochs):\n",
        "    # ... (training and evaluation code) ...\n",
        "    scheduler.step(test_losses[-1])  # Adjust the learning rate based on the latest validation loss\n",
        "    # Get and print the last learning rate\n",
        "    last_lr = scheduler.get_last_lr()[0]  # Access the learning rate\n",
        "    print(f\"Epoch {epoch + 1}, Last Learning Rate: {last_lr}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oxQQlVPAZktm"
      },
      "outputs": [],
      "source": [
        "pickle_path = f\"finetuned_models/{model_name}.pkl\"\n",
        "print(f\"Model pickled saved in {pickle_path}\")\n",
        "# Save the model using pickle\n",
        "torch.save(model, pickle_path)\n",
        "\n",
        "pth_path = f\"finetuned_models/{model_name}.pth\"\n",
        "print(f\"Model pth saved in {pth_path}\")\n",
        "torch.save(model.state_dict(), pth_path)\n",
        "\n",
        "# Define dummy input for ONNX export (batch size 1, 3 channels, 224x224 image size)\n",
        "dummy_input = torch.randn(1, 1, 224, 224).to(device)  # Move dummy input to GPU\n",
        "\n",
        "# Export the model to ONNX format\n",
        "onnx_path = f\"finetuned_models/{model_name}.onnx\"\n",
        "torch.onnx.export(model, dummy_input, onnx_path,\n",
        "                input_names=[\"input\"],\n",
        "                output_names=[\"output\"],\n",
        "                opset_version=11)\n",
        "\n",
        "print(f\"Model saved as onnx in {onnx_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghEkPs7NZktm"
      },
      "source": [
        "### Evaluate the trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 619
        },
        "id": "mhuP3qltZktm",
        "outputId": "0e25a09b-5ebd-4061-afd9-88665ffd6790"
      },
      "outputs": [],
      "source": [
        "model = load_model(filename=\"densenet169.pkl\", device=device)\n",
        "test_preds, test_labels = predict_model(model, test_loader, device)\n",
        "# Plot ROC curve for the test dataset\n",
        "plot_roc_curve(test_labels, test_preds, model_name='DenseNet169')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C7YO1uPgZktm"
      },
      "outputs": [],
      "source": [
        "from training_utils import load_model\n",
        "\n",
        "model = load_model(filename=\"stacked_model.pkl\", device=device)\n",
        "test_preds, test_labels = predict_model(model, test_loader, device)\n",
        "# Plot ROC curve for the test dataset\n",
        "plot_roc_curve(test_labels, test_preds, model_name='Stacked Model')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "049a759464ff4a41bfeaf92e476d501d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b0f02c1151b04c90b5ec62790893c1fa",
              "IPY_MODEL_3781a490ec5e4020a9d45e139b1b2348",
              "IPY_MODEL_dec47e76c2774ed0bddfb6a4be0bbc0f"
            ],
            "layout": "IPY_MODEL_a628d67cbf5948a680509e236f6aa364"
          }
        },
        "106921c8222d4618a3a3ffb22f24a4bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "140aa71728334ef1b1742a37d20162ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3781a490ec5e4020a9d45e139b1b2348": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7eb2e1c5b9d34f059418da50cacd37cd",
            "max": 1398,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_106921c8222d4618a3a3ffb22f24a4bc",
            "value": 1398
          }
        },
        "3f4c99b5d69c4dd4a10ecbf90fe308c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb9920d613d54a7ca2a36e49eec3c6dd",
            "max": 5589,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_140aa71728334ef1b1742a37d20162ed",
            "value": 5589
          }
        },
        "4a042298959142c7b8a2f9a4bc83bb1c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d167bd3c4424097a740baac320f209e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5be23f3309134bb0bfb42dd7b865df04": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "702ee58fe2fd4f83882e4e7ad22a436e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "782a80b6290d47af9ba652ec2265234b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7eb2e1c5b9d34f059418da50cacd37cd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8dc527440c604ac8a1d95313e796d5e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a042298959142c7b8a2f9a4bc83bb1c",
            "placeholder": "",
            "style": "IPY_MODEL_f083ef8e478c4e959bdc7f642a7d452a",
            "value": "Epoch1/1-Training:100%"
          }
        },
        "a628d67cbf5948a680509e236f6aa364": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0f02c1151b04c90b5ec62790893c1fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d167bd3c4424097a740baac320f209e",
            "placeholder": "",
            "style": "IPY_MODEL_e3e9d700db1b4272a16eca6b3efb9e40",
            "value": "Epoch1/1-Evaluation:100%"
          }
        },
        "b5e61be1e8e746baa0e4068b9622ce37": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_782a80b6290d47af9ba652ec2265234b",
            "placeholder": "",
            "style": "IPY_MODEL_702ee58fe2fd4f83882e4e7ad22a436e",
            "value": "5589/5589[16:15&lt;00:00,2.56batch/s]"
          }
        },
        "bb841543dea049cb97f93cc2ededba56": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8dc527440c604ac8a1d95313e796d5e3",
              "IPY_MODEL_3f4c99b5d69c4dd4a10ecbf90fe308c0",
              "IPY_MODEL_b5e61be1e8e746baa0e4068b9622ce37"
            ],
            "layout": "IPY_MODEL_5be23f3309134bb0bfb42dd7b865df04"
          }
        },
        "c764873684fc41d7948fdeee9d747220": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dec47e76c2774ed0bddfb6a4be0bbc0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c764873684fc41d7948fdeee9d747220",
            "placeholder": "",
            "style": "IPY_MODEL_f522c8effb784e9f8c1629d2c8507788",
            "value": "1398/1398[01:51&lt;00:00,14.51batch/s]"
          }
        },
        "e3e9d700db1b4272a16eca6b3efb9e40": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eb9920d613d54a7ca2a36e49eec3c6dd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f083ef8e478c4e959bdc7f642a7d452a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f522c8effb784e9f8c1629d2c8507788": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
